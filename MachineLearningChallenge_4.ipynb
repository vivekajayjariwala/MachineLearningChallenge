{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.239839Z",
     "start_time": "2024-05-21T15:32:43.922623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"hello\")"
   ],
   "id": "e4d631fd32d4fb2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.310988Z",
     "start_time": "2024-05-21T15:32:59.242363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Your custom column names\n",
    "column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "\n",
    "# Load the DataFrame, skipping the first row and directly assigning your custom column names\n",
    "df = pd.read_csv('data_train.csv', header=0)\n",
    "\n",
    "# Assign your custom column names\n",
    "df.columns = column_names"
   ],
   "id": "fbb5cb4a254051de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.324637Z",
     "start_time": "2024-05-21T15:32:59.312947Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "bdbc2ffa55953a4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25668, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.353885Z",
     "start_time": "2024-05-21T15:32:59.327636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# top 5 rows \n",
    "df.head()"
   ],
   "id": "543f236e42ed2084",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   index  restaurant_id  list_position  total_available_restaurants  \\\n",
       "0  19499             68             19                           26   \n",
       "1   5515            899              9                           29   \n",
       "2   5461           2964              2                           11   \n",
       "3   2868           1993             10                           14   \n",
       "4  26403             25             49                           50   \n",
       "\n",
       "   estimate_delivery_time     menu_category   star_rating  purchasers  \n",
       "0                      35  indian                      1           42  \n",
       "1                      20  italian                                 49  \n",
       "2                      20  american                    4           40  \n",
       "3                      25  indian                                  45  \n",
       "4                      45  indian                                  54  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>list_position</th>\n",
       "      <th>total_available_restaurants</th>\n",
       "      <th>estimate_delivery_time</th>\n",
       "      <th>menu_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>purchasers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19499</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5515</td>\n",
       "      <td>899</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>italian</td>\n",
       "      <td></td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5461</td>\n",
       "      <td>2964</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>american</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2868</td>\n",
       "      <td>1993</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>indian</td>\n",
       "      <td></td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26403</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>indian</td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.374399Z",
     "start_time": "2024-05-21T15:32:59.357878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop star_rating, too many missing values for it to be valuable \n",
    "df = df.drop(columns='index')\n",
    "# no missing values now \n",
    "df.isnull().sum()"
   ],
   "id": "7f5f516ee4c37142",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant_id                  0\n",
       "list_position                  0\n",
       "total_available_restaurants    0\n",
       "estimate_delivery_time         0\n",
       "menu_category                  0\n",
       "star_rating                    0\n",
       "purchasers                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.390534Z",
     "start_time": "2024-05-21T15:32:59.376398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['restaurant_id'] = df['restaurant_id'].astype('category')\n",
    "df.dtypes"
   ],
   "id": "b6b6eb170404eeb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant_id                  category\n",
       "list_position                     int64\n",
       "total_available_restaurants       int64\n",
       "estimate_delivery_time            int64\n",
       "menu_category                    object\n",
       "star_rating                      object\n",
       "purchasers                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.404770Z",
     "start_time": "2024-05-21T15:32:59.392533Z"
    }
   },
   "cell_type": "code",
   "source": "df['star_rating'].unique()",
   "id": "9d9c698bea607485",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['          1 ', '            ', '          4 ', '          3 ',\n",
       "       '          5 ', '          2 '], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.438310Z",
     "start_time": "2024-05-21T15:32:59.406761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['star_rating'] = df['star_rating'].str.strip()  # Remove leading and trailing whitespace\n",
    "df['star_rating'] = df['star_rating'].replace('', np.nan)  # Replace empty strings with NaN\n",
    "df['star_rating'] = df['star_rating'].astype(float)  # Convert to float\n",
    "df['star_rating'] = df['star_rating'].astype('category')  # Convert to categorical\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df['star_rating'].unique())"
   ],
   "id": "f6479e793a9a93ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, NaN, 4.0, 3.0, 5.0, 2.0]\n",
      "Categories (5, float64): [1.0, 2.0, 3.0, 4.0, 5.0]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:32:59.458582Z",
     "start_time": "2024-05-21T15:32:59.440301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['menu_category'] = label_encoder.fit_transform(df['menu_category'])\n",
    "df['star_rating'] = label_encoder.fit_transform(df['star_rating'])\n"
   ],
   "id": "ae50a30cbac334fc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:33:55.920835Z",
     "start_time": "2024-05-21T15:32:59.461166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define the models to be used\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Multi-Armed Bandit Approach\n",
    "def multi_armed_bandit(data, target, models):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize a dictionary to store the RMSE of each model\n",
    "    model_rmse = {model: [] for model in models}\n",
    "    \n",
    "    # Perform n_rounds of evaluation\n",
    "    for model_name, model in models.items():\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate RMSE and store it\n",
    "        rmse = calculate_rmse(y_test, y_pred)\n",
    "        model_rmse[model_name].append(rmse)\n",
    "    \n",
    "    # Calculate the average RMSE for each model\n",
    "    avg_rmse = {model: np.mean(rmses) for model, rmses in model_rmse.items()}\n",
    "    \n",
    "    # Create a DataFrame to display the results\n",
    "    results_df = pd.DataFrame(list(avg_rmse.items()), columns=['Model', 'Average RMSE'])\n",
    "    return results_df\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming your dataset is in a CSV file called 'data.csv' and the target column is 'target'\n",
    "data = df\n",
    "target = data.pop('purchasers')\n",
    "\n",
    "# Run the Multi-Armed Bandit approach\n",
    "results_df = multi_armed_bandit(data, target, models)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ],
   "id": "94f4b9e99e308c78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Average RMSE\n",
      "0       LinearRegression     34.047931\n",
      "1  DecisionTreeRegressor     47.976598\n",
      "2  RandomForestRegressor     35.972551\n",
      "3                    SVR     35.610104\n",
      "4    KNeighborsRegressor     35.499754\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:51.092134Z",
     "start_time": "2024-05-21T15:33:55.922828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('data_train.csv')\n",
    "# Your custom column names\n",
    "column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "# Assign your custom column names\n",
    "data.columns = column_names\n",
    "\n",
    "# Define the target and features\n",
    "target = data['purchasers']\n",
    "features = data.drop(columns=['purchasers'])\n",
    "\n",
    "# Preprocess the categorical features using OneHotEncoder\n",
    "categorical_features = ['restaurant_id', 'menu_category', 'star_rating']\n",
    "numeric_features = ['list_position', 'total_available_restaurants', 'estimate_delivery_time']\n",
    "\n",
    "# Column transformer to apply preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__max_depth': [5, 10, 20, None],\n",
    "    'model__min_samples_split': [2, 10, 20],\n",
    "    'model__min_samples_leaf': [1, 5, 10],\n",
    "    'model__max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Display the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'RMSE: {rmse}')"
   ],
   "id": "78526228f73c561e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__max_depth': None, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 5, 'model__min_samples_split': 20}\n",
      "RMSE: 33.854491242692184\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:34:56.808732Z",
     "start_time": "2024-05-21T15:34:51.097116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# \n",
    "# # Load your dataset\n",
    "# data = pd.read_csv('data_train.csv')\n",
    "# # Your custom column names\n",
    "# column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "# # Assign your custom column names\n",
    "# data.columns = column_names\n",
    "# \n",
    "# # Define the target and features\n",
    "# target = data['purchasers']\n",
    "# features = data.drop(columns=['purchasers'])\n",
    "# \n",
    "# # Preprocess the categorical features using OneHotEncoder\n",
    "# categorical_features = ['restaurant_id', 'menu_category', 'star_rating']\n",
    "# numeric_features = ['list_position', 'total_available_restaurants', 'estimate_delivery_time']\n",
    "# \n",
    "# # Column transformer to apply preprocessing steps\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "#         ('num', StandardScaler(), numeric_features)\n",
    "#     ])\n",
    "\n",
    "# Define the K-Neighbors Regressor model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 7],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a smaller subset for initial tuning\n",
    "X_train_sub, _, y_train_sub, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning with reduced number of folds\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Display the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'RMSE: {rmse}')"
   ],
   "id": "92b711e7b5f93e60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__algorithm': 'auto', 'model__n_neighbors': 7, 'model__weights': 'uniform'}\n",
      "RMSE: 36.01849398465335\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:45:20.945348Z",
     "start_time": "2024-05-21T15:45:19.324501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the Ridge Regression model\n",
    "model = Ridge()\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Display the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'RMSE: {rmse}')\n"
   ],
   "id": "201b1762f9186a7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__alpha': 10.0}\n",
      "RMSE: 32.2028266761723\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:49:53.003006Z",
     "start_time": "2024-05-21T15:49:49.826810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('data_train.csv')\n",
    "# Your custom column names\n",
    "column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "# Assign your custom column names\n",
    "data.columns = column_names\n",
    "\n",
    "# Define the target and features\n",
    "target = data['purchasers']\n",
    "features = data.drop(columns=['purchasers'])\n",
    "# Preprocess the categorical features using OneHotEncoder and numeric features using StandardScaler and PolynomialFeatures\n",
    "categorical_features = ['restaurant_id', 'menu_category', 'star_rating']\n",
    "numeric_features = ['list_position', 'total_available_restaurants', 'estimate_delivery_time']\n",
    "\n",
    "# Column transformer to apply preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "        ]), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the Ridge Regression model\n",
    "model = Ridge()\n",
    "\n",
    "# Create a pipeline with feature selection\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k='all')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'feature_selection__k': [10, 20, 'all'],\n",
    "    'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Display the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'RMSE: {rmse}')"
   ],
   "id": "138f2b79be0e04e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'feature_selection__k': 'all', 'model__alpha': 10.0}\n",
      "RMSE: 32.17273114631744\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:24:37.784118Z",
     "start_time": "2024-05-21T17:24:13.661767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('data_train.csv')\n",
    "# Your custom column names\n",
    "column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "# Assign your custom column names\n",
    "data.columns = column_names\n",
    "\n",
    "# Feature Engineering\n",
    "data['delivery_efficiency'] = data['estimate_delivery_time'] / (data['total_available_restaurants'] + 1)\n",
    "data['position_ratio'] = data['list_position'] / (data['total_available_restaurants'] + 1)\n",
    "# data['rating_position_interaction'] = data['star_rating'].astype(str) + \"_\" + data['list_position'].astype(str)\n",
    "# data['category_position_interaction'] = data['menu_category'].astype(str) + \"_\" + data['list_position'].astype(str)\n",
    "\n",
    "# Define the target and features\n",
    "target = data['purchasers']\n",
    "features = data.drop(columns=['purchasers'])\n",
    "\n",
    "# Preprocess the categorical features using OneHotEncoder and numeric features using StandardScaler and PolynomialFeatures\n",
    "categorical_features = ['restaurant_id', 'menu_category', 'star_rating']\n",
    "numeric_features = ['list_position', 'total_available_restaurants', 'estimate_delivery_time', 'delivery_efficiency', 'position_ratio']\n",
    "\n",
    "# Column transformer to apply preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "        ]), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the Ridge Regression model\n",
    "model = Ridge()\n",
    "\n",
    "# Create a pipeline with feature selection\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k='all')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'feature_selection__k': [10, 20, 'all'],\n",
    "    'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=45)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average RMSE from cross-validation\n",
    "cv_rmse = np.sqrt(-cv_scores).mean()\n",
    "\n",
    "# Display the results\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'RMSE on test set: {rmse}')\n",
    "print(f'Cross-validated RMSE: {cv_rmse}')"
   ],
   "id": "76a7eb3f3546e31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'feature_selection__k': 'all', 'model__alpha': 10.0}\n",
      "RMSE on test set: 31.719745298852118\n",
      "Cross-validated RMSE: 32.48199999820724\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:57.727861Z",
     "start_time": "2024-05-21T19:33:48.119706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('data_train.csv')\n",
    "\n",
    "# Your custom column names\n",
    "column_names = ['index', 'restaurant_id', 'list_position', 'total_available_restaurants', 'estimate_delivery_time', 'menu_category', 'star_rating', 'purchasers']\n",
    "data.columns = column_names\n",
    "\n",
    "# Feature Engineering\n",
    "data['delivery_efficiency'] = data['estimate_delivery_time'] / (data['total_available_restaurants'] + 1)\n",
    "data['position_ratio'] = data['list_position'] / (data['total_available_restaurants'] + 1)\n",
    "\n",
    "# Define the target and features\n",
    "target = data['purchasers']\n",
    "features = data.drop(columns=['purchasers'])\n",
    "\n",
    "# Preprocess the categorical features using OneHotEncoder and numeric features using StandardScaler and PolynomialFeatures\n",
    "categorical_features = ['restaurant_id', 'menu_category', 'star_rating']\n",
    "numeric_features = ['list_position', 'total_available_restaurants', 'estimate_delivery_time', 'delivery_efficiency', 'position_ratio']\n",
    "\n",
    "# Column transformer to apply preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "        ]), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create a pipeline with feature selection\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k='all')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=45)\n",
    "\n",
    "# Perform cross-validation to evaluate the model\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average RMSE from cross-validation\n",
    "cv_rmse = np.sqrt(-cv_scores).mean()\n",
    "\n",
    "# Display the results\n",
    "print(f'RMSE on test set: {rmse}')\n",
    "print(f'Cross-validated RMSE: {cv_rmse}')\n"
   ],
   "id": "8ed860f8e0992a41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 32.10657353439663\n",
      "Cross-validated RMSE: 32.835520221096665\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32268deee636d398"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
